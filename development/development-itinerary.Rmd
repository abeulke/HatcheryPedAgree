---
title: 'Itinerary for package development'
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




# Topics for discussion during meetings

## For: Tuesday, May 19, 2020

### 1. Data set format

Laura and Anne, here is the format we want the main, initial datasets to be in:

* A tibble of genotypes that must have _at least_ these columns:
    1. `indiv`: the individual ID (could be, for example, the NMFS_DNA_ID
    2. `locus`: the name of the locus
    3. `gene_copy`: a column of 1's and 2's
    4. `allele_int`: a column of alleles, 1-4, with 0 for missing data.
    
    These columns can be in any order, but ordered as above is natural.
Note that the genotypes can contain more columns.  For example, it could have a full
microhaplotype allele column, etc.  But for the SNP data sets, we don't really
need another one.

* A tibble of metadata relevant to the parentage. At this point I am thinking
that this includes:
    1. `indiv`
    2. `sex` a column of Male, Female, or NA
    3. `spawner_group`: typically the data of collection/spawning
    4. `year`: the year the individual was sampled/spawned
    
    Anne and Laura, can you think of anything else that belongs in here?
    
An example of these two data files can be found now by loading the package
which gives access to `coho_genotypes` and `coho_metadata`.  (You will have to pull
from upstream to master and load that version).

### 2. Let's talk about the `data` folder and `data.R`

* Just make sure we understand how package data can work.
* Talk about `extdata` too.

### 3. Matching samples

We need to do a few things here:

1. Function to convert to rubias format
2. Run rubias to find matching samples.
3. Find connected components.
4. Figure out which of the version of the individuals will be kept as the
canonical genotype.  

Along the way, we will want to investigate the results.  So, we will break this
down into different functions.

Here are some things to read about that we will use:

* [pivoting](https://tidyr.tidyverse.org/articles/pivot.html).  This is gather/spread, but on steroids.  New
from the 'tidyr' package.
* [tidygraph](https://www.data-imaginist.com/2017/introducing-tidygraph/) Thomas Lin Pedersen's tidyverse 
solution to handling graphs and networks. TLP was an intern with Hadley at RStudio when he did gganinmate.
Now, he is still with RStudio, I think, and does amazing work.

I need you guys to get your steelhead data sets into that format so we can
have those to test on.


### 4. A little bit about NSE and rlang::enquo()

Weird stuff, but it will let us convert to rubias with microhaps, when we have those.

### 5. R CMD Check

Two main points here:

* Namespace addressing and Imports in Description.
* Visible bindings for 'global' variables.




## Thursday, May 14, 2020

### 1. Installing packages

Make sure this is done:
```r
install.packages(c("devtools", "roxygen2", "testthat", "knitr", "styler"))
```

### 2. Code style

This is **mandatory** reading: 
[https://style.tidyverse.org/](https://style.tidyverse.org/), at least, for
now, Chapters 1--7.

### 3. Roxygen

Make sure that the configurations are done on their projects. See and
follow directions at:  
[https://r-pkgs.org/man.html#man-workflow-2](https://r-pkgs.org/man.html#man-workflow-2)

Note that we have:
```
Roxygen: list(markdown = TRUE)
```
in the `DESCRIPTION` file.


### 4. Forking and Pull requests

Let's follow through the packages book.

```sh
git config --global merge.conflictstyle diff3
```

Also set up upstream:
```sh
git remote add upstream https://github.com/eriqande/HatcheryPedAgree.git
```

Then, any time you want to get new commits from the upstream repo, you do:
```sh
git fetch upstream
```
That "fetches" the objects.

And, to merge them into your current branch, once they are fetched, you do:
```sh
git merge upstream/master
```

To be able to pull upstream into the current branch, you can set that up
with:
```sh
git branch -u upstream/master   
```

Then, to pull it into master you can:
```sh
git checkout master
git pull
```

To make it easier to work with branches, we installed
`.git-prompt.sh` and updates `PS1` to show the branch on our
bash prompt.




Be sure to get `upstream` set up.  Then run through the pull request procedure.


### 5. Data sets 

What format are these currently in?  I want to to have both of
the steelhead data sets in a canonical form to be in this project,
but have them gitignored. Then I will put the coho SNPs up on GitHub
for running through examples, etc.

I will send a specification of what I want, once I have figured
that out, and then Anne and Laura can email those to me and I can put them
together in a directory that we can send out to everyone.  That way we
can all test new functions on these private data sets.

**DON'T COMMIT THESE DATA SETS TO THE REPO!**


